{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenización por caracteres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, GRU, Embedding, Dropout\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset canciones de bandas de habla inglés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7amy6uUaBLVD"
      },
      "outputs": [],
      "source": [
        "# descargar de textos.info\n",
        "import urllib.request\n",
        "\n",
        "# Para leer y parsear el texto en HTML de wikipedia\n",
        "import bs4 as bs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6v_ickFwBJTy"
      },
      "outputs": [],
      "source": [
        "raw_html = urllib.request.urlopen('https://www.textos.info/oscar-wilde/el-retrato-de-dorian-gray/ebook')\n",
        "raw_html = raw_html.read()\n",
        "\n",
        "# Parsear artículo, 'lxml' es el parser a utilizar\n",
        "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "\n",
        "# Encontrar todos los párrafos del HTML (bajo el tag <p>)\n",
        "# y tenerlos disponible como lista\n",
        "article_paragraphs = article_html.find_all('p')\n",
        "\n",
        "article_text = ''\n",
        "\n",
        "for para in article_paragraphs:\n",
        "    article_text += para.text + ' '\n",
        "\n",
        "# pasar todo el texto a minúscula\n",
        "article_text = article_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "WBE0sSYuB-E6",
        "outputId": "a128ff45-b9a8-4c6e-d022-c2a4cd8825be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' el artista es creador de belleza. revelar el arte y ocultar al artista es la meta del arte. el crítico es quien puede traducir de manera distinta o con nuevos \\r\\nmateriales su impresión de la belleza. la forma más elevada de la \\r\\ncrítica, y también la más rastrera, es una modalidad de autobiografía. quienes descubren significados ruines en cosas hermosas están \\r\\ncorrompidos sin ser elegantes, lo que es un defecto. quienes encuentran \\r\\nsignificados bellos en cosas hermosas son espíritus cultivados. para \\r\\nellos hay esperanza. son los elegidos, y en su caso las cosas hermosas sólo significan belleza. no existen libros morales o inmorales. los libros están bien o mal escritos. eso es todo. la aversión del siglo por el realismo es la rabia de calibán al verse la cara en el espejo. la aversión del siglo por el romanticismo es la rabia de calibán al no verse la cara en un espejo. la vida moral del hombre forma parte de los temas del artista, pero \\r\\nla moralidad del arte consiste en hacer un '"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# en article text se encuentra el texto de todo el libro\n",
        "article_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
        "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(article_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwTK6xgLJd8q",
        "outputId": "8588e28f-28e5-49cd-9df6-bf53d1472e69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwGVSKOiJ5bj",
        "outputId": "eb68980b-f7f8-4410-d2af-8c11ec00677b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[57, 40, 2, 57, 1, 35, 45, 6, 25, 45]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_text[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WSSmg9jtKP0T"
      },
      "outputs": [],
      "source": [
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NmxQdxl8LRCg"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vken7O4ETsAJ"
      },
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
        "\n",
        "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
        "\n",
        "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFAyA4zCWE-5",
        "outputId": "e2e304a2-1a97-41ff-a41e-322ceea24c93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(419061, 100)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcKRl70HFTzG",
        "outputId": "68ba8550-a1ed-480e-f70f-de551f268e04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([57, 40,  2, 57,  1, 35, 45,  6, 25, 45])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVpLCKSZFXZO",
        "outputId": "d35e81df-b071-49b0-905b-da2ae6dac834"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([40,  2, 57,  1, 35, 45,  6, 25, 45,  1])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wOFCR-KqbW1N"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(chars_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "# Definiendo el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rkMCZvmhrQz4"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
        "from keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgz7VKwTUbj6"
      },
      "source": [
        "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas `CategoryEncoding` que transforma a índices a vectores OHE y `TimeDistributed` que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd2OkfQYs2Q7",
        "outputId": "4c8750c9-a131-4c93-d6e5-6f3f909cba94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed (TimeDistr  (None, None, 65)         0         \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, None, 200)         53200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 65)          13065     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,265\n",
            "Trainable params: 66,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "\n",
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK3z85sQfUe"
      },
      "source": [
        "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
        "\n",
        "**Nota**: un Callback es una rutina gatillada por algún evento, son muy útiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cálculo cada vez que termina una epoch de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zUHX3r5JD-MG"
      },
      "outputs": [],
      "source": [
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data, history_ppl,patience=5,model_name='my_model'):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.val_data = val_data\n",
        "\n",
        "      self.target = []\n",
        "      self.padded = []\n",
        "\n",
        "      count = 0\n",
        "      self.info = []\n",
        "      self.model_name = model_name\n",
        "      self.min_score = np.inf\n",
        "      self.patience_counter = 0\n",
        "      self.patience = patience\n",
        "\n",
        "      # nos movemos en todas las secuencias de los datos de validación\n",
        "      for seq in self.val_data:\n",
        "\n",
        "        len_seq = len(seq)\n",
        "        # armamos todas las subsecuencias\n",
        "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
        "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
        "\n",
        "        if len(subseq)!=0:\n",
        "\n",
        "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
        "\n",
        "          self.info.append((count,count+len_seq))\n",
        "          count += len_seq\n",
        "\n",
        "      self.padded = np.vstack(self.padded)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        predictions = self.model.predict(self.padded,verbose=0, batch_size=2048)\n",
        "\n",
        "        # para cada secuencia de validación\n",
        "        for start,end in self.info:\n",
        "\n",
        "          # en `probs` iremos guardando las probabilidades de los términos target\n",
        "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        current_score = np.mean(scores)\n",
        "        history_ppl.append(current_score)\n",
        "        print(f'\\n mean perplexity: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que detener el entrenamiento\n",
        "        if current_score < self.min_score:\n",
        "          self.min_score = current_score\n",
        "          self.model.save(self.model_name)\n",
        "          print(\"Saved new model!\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == self.patience:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQq1PHDkxDvN",
        "outputId": "7cb7856e-648f-4317-b5b0-5cecd4a7074e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.2680\n",
            " mean perplexity: 8.074709427003222 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 40s 193ms/step - loss: 2.2680\n",
            "Epoch 2/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.1381\n",
            " mean perplexity: 7.422574611110533 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 2.1381\n",
            "Epoch 3/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.0573\n",
            " mean perplexity: 6.772387428075349 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 2.0573\n",
            "Epoch 4/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.9875\n",
            " mean perplexity: 6.325850754296115 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 39s 189ms/step - loss: 1.9875\n",
            "Epoch 5/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.9320\n",
            " mean perplexity: 5.945295875391227 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 38s 186ms/step - loss: 1.9320\n",
            "Epoch 6/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.8886\n",
            " mean perplexity: 5.716040637898186 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 1.8886\n",
            "Epoch 7/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.8555\n",
            " mean perplexity: 5.58787719923396 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 39s 190ms/step - loss: 1.8555\n",
            "Epoch 8/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.8298\n",
            " mean perplexity: 5.414363385883616 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 1.8298\n",
            "Epoch 9/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.8094\n",
            " mean perplexity: 5.344579829151268 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 39s 191ms/step - loss: 1.8094\n",
            "Epoch 10/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7932\n",
            " mean perplexity: 5.224559385602692 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 1.7932\n",
            "Epoch 11/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7801\n",
            " mean perplexity: 5.148923876726183 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 38s 187ms/step - loss: 1.7801\n",
            "Epoch 12/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7690\n",
            " mean perplexity: 5.1176421889031944 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 38s 186ms/step - loss: 1.7690\n",
            "Epoch 13/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7600\n",
            " mean perplexity: 5.057035582619904 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 1.7600\n",
            "Epoch 14/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7521\n",
            " mean perplexity: 5.018991375810428 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 39s 188ms/step - loss: 1.7521\n",
            "Epoch 15/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7459\n",
            " mean perplexity: 4.972970964421029 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 38s 187ms/step - loss: 1.7459\n",
            "Epoch 16/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7397\n",
            " mean perplexity: 4.9325528653663655 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 38s 187ms/step - loss: 1.7397\n",
            "Epoch 17/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7348\n",
            " mean perplexity: 4.900822614522716 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 37s 178ms/step - loss: 1.7348\n",
            "Epoch 18/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7304\n",
            " mean perplexity: 4.897161152144887 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 37s 180ms/step - loss: 1.7304\n",
            "Epoch 19/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7262\n",
            " mean perplexity: 4.877621375676491 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 37s 180ms/step - loss: 1.7262\n",
            "Epoch 20/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7225\n",
            " mean perplexity: 4.847917204527797 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_Elman\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 1.7225\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl,5,'my_model_Elman')], batch_size=2048)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "K30JHB3Dv-mx",
        "outputId": "67fa87ee-7877-467c-a4d0-586ee054d214"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgXXH9qpAM1Y"
      },
      "source": [
        "###Usando LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCIVbk9t_-zd",
        "outputId": "9bbba9f6-0ee4-4b2b-ce5d-39a069194596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_1 (TimeDis  (None, None, 65)         0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, None, 200)         212800    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, None, 65)          13065     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 225,865\n",
            "Trainable params: 225,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model1 = Sequential()\n",
        "\n",
        "model1.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model1.add(LSTM(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model1.add(Dense(vocab_size, activation='softmax'))\n",
        "model1.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2YkJlUCAH_s",
        "outputId": "563a1a3b-cd15-4287-a201-b17825734741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.8192\n",
            " mean perplexity: 11.402097999109738 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 131s 625ms/step - loss: 2.8192\n",
            "Epoch 2/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.3162\n",
            " mean perplexity: 8.883076891465363 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 126s 615ms/step - loss: 2.3162\n",
            "Epoch 3/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.1526\n",
            " mean perplexity: 7.772527012993605 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 127s 617ms/step - loss: 2.1526\n",
            "Epoch 4/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.0411\n",
            " mean perplexity: 7.117497972634929 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 127s 619ms/step - loss: 2.0411\n",
            "Epoch 5/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.9486\n",
            " mean perplexity: 6.560629582566296 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 128s 626ms/step - loss: 1.9486\n",
            "Epoch 6/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.8693\n",
            " mean perplexity: 6.097295265543618 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 128s 624ms/step - loss: 1.8693\n",
            "Epoch 7/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.8008\n",
            " mean perplexity: 5.802527901984603 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 128s 624ms/step - loss: 1.8008\n",
            "Epoch 8/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7419\n",
            " mean perplexity: 5.585914199426185 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 129s 628ms/step - loss: 1.7419\n",
            "Epoch 9/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.6909\n",
            " mean perplexity: 5.321471236559993 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 128s 622ms/step - loss: 1.6909\n",
            "Epoch 10/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.6467\n",
            " mean perplexity: 5.154889804124064 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 129s 628ms/step - loss: 1.6467\n",
            "Epoch 11/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.6085\n",
            " mean perplexity: 4.985971722993338 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 127s 618ms/step - loss: 1.6085\n",
            "Epoch 12/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.5753\n",
            " mean perplexity: 4.874993652438847 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 126s 615ms/step - loss: 1.5753\n",
            "Epoch 13/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.5460\n",
            " mean perplexity: 4.7532309842526015 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 128s 623ms/step - loss: 1.5460\n",
            "Epoch 14/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.5203\n",
            " mean perplexity: 4.691875481910058 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 128s 625ms/step - loss: 1.5203\n",
            "Epoch 15/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.4976\n",
            " mean perplexity: 4.625132213609457 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 128s 625ms/step - loss: 1.4976\n",
            "Epoch 16/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.4779\n",
            " mean perplexity: 4.593780481358149 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 127s 621ms/step - loss: 1.4779\n",
            "Epoch 17/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.4600\n",
            " mean perplexity: 4.531926746866873 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 126s 616ms/step - loss: 1.4600\n",
            "Epoch 18/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.4440\n",
            " mean perplexity: 4.512218684300779 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 127s 622ms/step - loss: 1.4440\n",
            "Epoch 19/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.4298\n",
            " mean perplexity: 4.489324032793984 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 128s 626ms/step - loss: 1.4298\n",
            "Epoch 20/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.4168\n",
            " mean perplexity: 4.474309006165637 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_LSTM\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 127s 621ms/step - loss: 1.4168\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model1.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl,5,'my_model_LSTM')], batch_size=2048)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "_FmDnCUoAMMt",
        "outputId": "dba02cdc-5eaf-4ae7-b315-0a16da5e9e26"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IkfVTlUAUK7"
      },
      "source": [
        "### Usando GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF2HYAtAATcE",
        "outputId": "5bce4946-6be8-4668-ec75-701023a2ecce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_2 (TimeDis  (None, None, 65)         0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " gru (GRU)                   (None, None, 200)         160200    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, None, 65)          13065     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 173,265\n",
            "Trainable params: 173,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "model2.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model2.add(GRU(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model2.add(Dense(vocab_size, activation='softmax'))\n",
        "model2.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJu4_yB2AZ2X",
        "outputId": "3d25fbaf-f86c-4ec7-8deb-ca33e468fd7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.6317\n",
            " mean perplexity: 9.201618234409427 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 125s 600ms/step - loss: 2.6317\n",
            "Epoch 2/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.1642\n",
            " mean perplexity: 7.570274866288409 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 118s 576ms/step - loss: 2.1642\n",
            "Epoch 3/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.9987\n",
            " mean perplexity: 6.707766900286934 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 119s 582ms/step - loss: 1.9987\n",
            "Epoch 4/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.8734\n",
            " mean perplexity: 6.00923620620439 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 120s 584ms/step - loss: 1.8734\n",
            "Epoch 5/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7738\n",
            " mean perplexity: 5.591029268530212 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 120s 584ms/step - loss: 1.7738\n",
            "Epoch 6/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.6955\n",
            " mean perplexity: 5.238282523823754 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 115s 563ms/step - loss: 1.6955\n",
            "Epoch 7/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.6358\n",
            " mean perplexity: 5.051556935527171 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 116s 568ms/step - loss: 1.6358\n",
            "Epoch 8/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.5892\n",
            " mean perplexity: 4.881281328379528 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 117s 570ms/step - loss: 1.5892\n",
            "Epoch 9/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.5529\n",
            " mean perplexity: 4.753847959566464 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 113s 550ms/step - loss: 1.5529\n",
            "Epoch 10/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.5232\n",
            " mean perplexity: 4.668394923387975 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 112s 548ms/step - loss: 1.5232\n",
            "Epoch 11/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.4992\n",
            " mean perplexity: 4.570617802988107 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 112s 546ms/step - loss: 1.4992\n",
            "Epoch 12/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.4791\n",
            " mean perplexity: 4.515086934052438 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 112s 546ms/step - loss: 1.4791\n",
            "Epoch 13/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.4624\n",
            " mean perplexity: 4.466024346711268 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 112s 548ms/step - loss: 1.4624\n",
            "Epoch 14/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.4483\n",
            " mean perplexity: 4.43707327151434 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 113s 549ms/step - loss: 1.4483\n",
            "Epoch 15/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.4361\n",
            " mean perplexity: 4.38668167915452 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 112s 546ms/step - loss: 1.4361\n",
            "Epoch 16/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.4256\n",
            " mean perplexity: 4.347282994531414 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 112s 546ms/step - loss: 1.4256\n",
            "Epoch 17/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.4166\n",
            " mean perplexity: 4.3303050374676895 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 110s 539ms/step - loss: 1.4166\n",
            "Epoch 18/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.4085\n",
            " mean perplexity: 4.297212144096078 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 110s 534ms/step - loss: 1.4085\n",
            "Epoch 19/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.4013\n",
            " mean perplexity: 4.285065770215184 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 110s 538ms/step - loss: 1.4013\n",
            "Epoch 20/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3947\n",
            " mean perplexity: 4.277775118960385 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n",
            "Saved new model!\n",
            "205/205 [==============================] - 118s 578ms/step - loss: 1.3947\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model2.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl,5,'my_model_GRU')], batch_size=2048)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "XLaeR5T4Ac7A"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1FklEQVR4nO3deXhU9d3//9fMJDPZJ2QjCQlhB0VklYhrb+WrUqu4fLUibbUubS1W7d32Uq/ra9Wfv97c2t7+/GotrVaRVuWu3m61tlJAxKossgqi7EtWAgnZk5lk5vz+mGQgQkImmZkzy/NxXXNNMnPmzPtwGObF57zP+VgMwzAEAAAQBFazCwAAALGDYAEAAIKGYAEAAIKGYAEAAIKGYAEAAIKGYAEAAIKGYAEAAIKGYAEAAIImIdxv6PV6VVlZqfT0dFkslnC/PQAAGADDMNTU1KTCwkJZrb2PS4Q9WFRWVqq4uDjcbwsAAIKgrKxMRUVFvT4f9mCRnp4uyVdYRkZGuN8eAAAMQGNjo4qLi/3f470Je7DoPvyRkZFBsAAAIMqcro2B5k0AABA0BAsAABA0BAsAABA0BAsAABA0BAsAABA0BAsAABA0BAsAABA0BAsAABA0BAsAABA0BAsAABA0BAsAABA0BAsAABA0MREs3J1ePffRXi14dZNcnR6zywEAIG7FRLBItFn0+9X79N7nVfqyqsnscgAAiFsxESwsFosmFzklSVsOHTO5GgAA4ldMBAtJmlycKUnaUlZvah0AAMSzmAkWU7qCxdbyBnMLAQAgjsVMsJhclClJ2n+0RfWtbnOLAQAgTsVMsBiSateI7BRJjFoAAGCWmAkW0vHDIVsO1ZtaBwAA8SqmgsVkf59Fval1AAAQr2IqWEw54cwQwzDMLQYAgDgUU8HijIIMJdosqmtxq6yuzexyAACIOwEHi6amJt13330qKSlRcnKyzjvvPH322WehqC1gSYk2nVmQIUnawuEQAADCLuBgcccdd2j58uX685//rG3btumyyy7T7NmzVVFREYr6AkYDJwAA5gkoWLS1temNN97QE088oYsuukhjxozRI488ojFjxmjRokWhqjEgNHACAGCehEAW7uzslMfjUVJSUo/Hk5OT9fHHH5/yNS6XSy6Xy/97Y2PjAMrsv+4Ri+0VDerweJVoi6k2EgAAIlpA37rp6emaNWuWHnvsMVVWVsrj8ejll1/WmjVrVFVVdcrXLFy4UE6n038rLi4OSuG9GZGdqoykBLk6vdpZzUynAACEU8D/nf/zn/8swzA0bNgwORwOPf3005o3b56s1lOv6sEHH1RDQ4P/VlZWNuii+2K1WvyHQzYzIRkAAGEVcLAYPXq0Vq9erebmZpWVlWn9+vXq6OjQqFGjTrm8w+FQRkZGj1uo0cAJAIA5BtyAkJqaqoKCAh07dkzLli3T3Llzg1nXoEyhgRMAAFME1LwpScuWLZNhGBo/frz27NmjX/ziF5owYYK+//3vh6K+Aek+FLL3SLMa2zuUkZRobkEAAMSJgEcsGhoatGDBAk2YMEHf+973dMEFF2jZsmVKTIycL++cNIeKhiTLMKRtzHQKAEDYBDxiceONN+rGG28MRS1BNaU4U+XH2rSlrF7nj8kxuxwAAOJCzF7k4cQJyQAAQHjERbBgplMAAMIjZoPFxEKnbFaLjjS5VNnQbnY5AADEhZgNFsl2mybkp0uStnI4BACAsIjZYCHRZwEAQLjFdLCYTLAAACCsYjpYTO0KFtvKG9Tp8ZpbDAAAcSCmg8Wo3DSlORLU1uHRrsPNZpcDAEDMi+lgYbNadHaRUxLzhgAAEA4xHSykE/osmOkUAICQi/lgwUynAACET8wHi+4Gzl2Hm9Ti6jS3GAAAYlzMB4u8jCQVOJPkNaRtFcx0CgBAKMV8sJC4UBYAAOESF8GCBk4AAMIjLoIFDZwAAIRHXASLScOcslqkqoZ2HW5kplMAAEIlLoJFqiNB44b6ZjqlzwIAgNCJi2Ah0cAJAEA4xE2w6G7g3EqwAAAgZOImWHSPWHxe3iCP1zC3GAAAYlTcBIuxeWlKTrSp2dWpvUeY6RQAgFCIm2CRYLNqUtdMp/RZAAAQGnETLKTj84YQLAAACI24ChY0cAIAEFpxFSy6Gzi/qm5Sm9tjbjEAAMSguAoWBc4k5aY75PEa+qKSmU4BAAi2uAoWFouFC2UBABBCcRUspOOHQzYTLAAACLq4DRY0cAIAEHxxFywmFTllsUjlx9p0tNlldjkAAMSUuAsWGUmJGp2bJolRCwAAgi3ugoXETKcAAIRKXAaLyQQLAABCIi6DxdQTGji9zHQKAEDQxGWwGJ+fLkeCVY3tndpf22J2OQAAxIy4DBaJNqvOGuab6ZQGTgAAgicug4VEAycAAKEQt8GCmU4BAAi+uA0W3Q2cO6oa1d7BTKcAAARD3AaLoiHJykq1q8Nj6MuqRrPLAQAgJsRtsGCmUwAAgi9ug4UkTS7KlESwAAAgWOI6WEwZnimJBk4AAIIlroPF5CLftSwO1LbqWIvb5GoAAIh+cR0sMlPsGpmTKknaWl5vbjEAAMSAuA4WEhfKAgAgmOI+WHQfDiFYAAAweHEfLKYMHyLJ18BpGMx0CgDAYMR9sDijIF12m1XHWjt0qK7V7HIAAIhqcR8sHAk2nVGYIYnDIQAADFbcBwvp+LwhBAsAAAaHYCFpcrGvgZMLZQEAMDgEC0lTin0NnNsrG+Xu9JpcDQAA0YtgIWlEdoqcyYlyd3r1VTUznQIAMFAEC/lmOp3c1WfB4RAAAAaOYNGl+wqcmwkWAAAMWEDBwuPx6KGHHtLIkSOVnJys0aNH67HHHouJC0tNoYETAIBBSwhk4ccff1yLFi3SkiVLNHHiRG3YsEHf//735XQ6dc8994SqxrCYXJQpSdp7pEUNbR1yJieaWxAAAFEooGDx6aefau7cubryyislSSNGjNDSpUu1fv36kBQXTtlpDhVnJausrk3byht0wdgcs0sCACDqBHQo5LzzztPKlSu1a9cuSdLWrVv18ccfa86cOb2+xuVyqbGxscctUnWfdrql7JjJlQAAEJ0CGrF44IEH1NjYqAkTJshms8nj8ehXv/qV5s+f3+trFi5cqEcffXTQhYbD5CKn3t1ayRU4AQAYoIBGLF577TW98sorevXVV7Vp0yYtWbJEv/nNb7RkyZJeX/Pggw+qoaHBfysrKxt00aEydXimJGlLWUNMNKQCABBuAY1Y/OIXv9ADDzygm266SZI0adIkHTx4UAsXLtQtt9xyytc4HA45HI7BVxoGEwudSrBadLTZpYr6NhUNSTG7JAAAokpAIxatra2yWnu+xGazyeuNjctgJyXaNKEgXZK0tazB5GoAAIg+AQWLq666Sr/61a/03nvv6cCBA3rrrbf05JNP6tprrw1VfWE3xT/TKQ2cAAAEKqBDIc8884weeugh/fjHP1ZNTY0KCwv1wx/+UL/85S9DVV/YTS7K1Ms6xIgFAAADEFCwSE9P11NPPaWnnnoqROWYr7uBc1tFgzo9XiXYuOo5AAD9xbfm14zKSVO6I0FtHR7tPNxkdjkAAEQVgsXXWK0Wne2fN4TDIQAABIJgcQo0cAIAMDAEi1PonpCMEQsAAAJDsDiF7hGLXTVNanZ1mlsMAABRhGBxCnkZSSp0JskwpG3ljFoAANBfBIteTPHPG1Jvah0AAEQTgkUvuvssaOAEAKD/CBa96O6zoIETAID+I1j0YlKRU1aLVN3YruqGdrPLAQAgKhAsepFiT9C4ob6ZTumzAACgfwgWfZhKAycAAAEhWPTh+IWy6k2tAwCAaEGw6EP3Kaefl9fL4zXMLQYAgChAsOjD2Lx0pdhtanF7tKem2exyAACIeASLPtisFk0a1j3Tab25xQAAEAUIFqfRfThkM8ECAIDTIlicxhQaOAEA6DeCxWl0j1jsPNykNrfH3GIAAIhwBIvTyM9IUl66Qx6voe2VXN4bAIC+ECxOw2Kx+OcN2XKo3tRaAACIdASLfpjcHSzoswAAoE8Ei36Y2hUsNhysk5cLZQEA0CuCRT9MKxmijKQEHW506aPdR8wuBwCAiEWw6IekRJuun14kSXp13SGTqwEAIHIRLPppfulwSdLKr2pU3dBucjUAAEQmgkU/jclL18wRWfJ4Df3lszKzywEAICIRLAJwc9eoxV8+O8RspwAAnALBIgBXnJWvISmJqmxo14c7a8wuBwCAiEOwCEBSok3/myZOAAB6RbAI0LyZvsMhq3bWqKK+zeRqAACILASLAI3KTdOsUdnyGtJf1jNqAQDAiQgWA+Bv4txQpk6P1+RqAACIHASLAbh8Yr6yU+063OjSyq9o4gQAoBvBYgDsCVbdMKNYEk2cAACciGAxQPNm+oLFR7uPqKyu1eRqAACIDASLASrJTtWFY3NkGNJSmjgBAJBEsBiUm7tOPX1tQ7k6aOIEAIBgMRizzxyq3HSHjja7tHzHYbPLAQDAdASLQUi0WfVtmjgBAPAjWAzSTTOLZbFIH+85qgNHW8wuBwAAUxEsBqloSIouHpcriSZOAAAIFkHQ3cT5+sZyuTo9JlcDAIB5CBZBcMmEPOVnJKmuxa1lX9DECQCIXwSLIEiwWfXtc3xNnK+sPWhyNQAAmIdgESQ3zSyW1SKt21+nPTXNZpcDAIApCBZBUuBM1iUT8iTRxAkAiF8EiyDqnk79jU3lau+giRMAEH8IFkF08bg8DctMVn1rh/6xvcrscgAACDuCRRDZrBbd5G/i5HAIACD+ECyC7MZzimWzWrTh4DHtOtxkdjkAAIQVwSLIhmYkafYZviZO5g8BAMQbgkUI3FxaIsnXxNnmpokTABA/CBYhcOGYHBVnJaupvVPvfl5pdjkAAIQNwSIErFaL5nXNH8LhEABAPCFYhMgN04uVYLVoS1m9dlQ2ml0OAABhQbAIkdx0hy6fmC9JenU984cAAOIDwSKE5nddifPtzZVqcXWaXA0AAKEXULAYMWKELBbLSbcFCxaEqr6oNmt0tkbmpKrZ1am/bqWJEwAQ+wIKFp999pmqqqr8t+XLl0uSbrjhhpAUF+0sFovmzfRdiZMmTgBAPAgoWOTm5io/P99/+9vf/qbRo0fr4osvDlV9Ue9/Ty+W3WbVtooGbStvMLscAABCasA9Fm63Wy+//LJuu+02WSyWXpdzuVxqbGzscYsnWal2XXEWTZwAgPgw4GDx9ttvq76+Xrfeemufyy1cuFBOp9N/Ky4uHuhbRq3uJs53tlSqqb3D5GoAAAidAQeLF154QXPmzFFhYWGfyz344INqaGjw38rKygb6llFr5sgsjclLU6vbo7e30MQJAIhdAwoWBw8e1IoVK3THHXecdlmHw6GMjIwet3jja+I8fiVOwzBMrggAgNAYULBYvHix8vLydOWVVwa7nph1/bRhsidY9WVVo7aU1ZtdDgAAIRFwsPB6vVq8eLFuueUWJSQkhKKmmJSZYte3JhVI4tRTAEDsCjhYrFixQocOHdJtt90Winpi2vxzfYdD3v28Ug1tNHECAGJPwMHisssuk2EYGjduXCjqiWnThg/R+KHpau/w6q1N5WaXAwBA0DFXSBhZLBbd3HXq6avraeIEAMQegkWYXTN1mJISrdp1uFkbDx4zuxwAAIKKYBFmzuREXT3Zd+2PV2jiBADEGIKFCW4uLZEkvbetSsda3CZXAwBA8BAsTDC5yKkzCzLk7vTqDZo4AQAxhGBhApo4AQCximBhkrlTCpVit2nfkRat219ndjkAAAQFwcIk6UmJmjtlmCSaOAEAsYNgYaLu6dTf316l2maXydUAADB4BAsTnTXMqbOLnOrwGPqfjTRxAgCiH8HCZDd3Tae+dP0heb00cQIAohvBwmRXTS5UmiNBB2pbtWZfrdnlAAAwKAQLk6U6EnTtVF8T5+JP9ptcDQAAg0OwiAC3nj9CVou04ssaba9oMLscAAAGjGARAUbnpumqrvlD/u/K3SZXAwDAwBEsIsRPLhkri0VavuMwoxYAgKhFsIgQY/LSdNXZvlGLpxm1AABEKYJFBLnn0jGyWKR/7jisLyoZtQAARB+CRQQZk5eubzFqAQCIYgSLCHPPJb5Ri2VfHNaOykazywEAICAEiwgzdmi6rpxUIIlRCwBA9CFYRKB7LvWdIfL+F9X6sopRCwBA9CBYRKBxQ9P1TUYtAABRiGARoe7puq7FP7ZX66tqRi0AANGBYBGhxuen65tnMWoBAIguBIsI9pNLx0iS/r6tWjurm0yuBgCA0yNYRLAJ+Rn65qR8SYxaAACiA8Eiwt1z6VhJ0t+3VzFqAQCIeASLCDchP0NzzsqXYUhPf8CoBQAgshEsooB/1GJblXYfZtQCABC5CBZR4IyCDF0xsXvUYo/Z5QAA0CuCRZToHrX42+eVjFoAACIWwSJKnFmYocsnDpVhSM8wagEAiFAEiyjSPWrx7ueV2lPDqAUAIPIQLKLIxEKnLjuTUQsAQOQiWESZ7lGLv26t1J6aZpOrAQCgJ4JFlDlrmFOzz/CNWvyW61oAACIMwSIK3Tf7+KjF3iOMWgAAIgfBIgr5Ri3y5DWk39JrAQCIIASLKHXvpeMkSe9sqdA+Ri0AABGCYBGlJhU5dekERi0AAJGFYBHF7u3qtXibUQsAQIQgWESxs4sydUn3qMUqRi0AAOYjWES5e7uua/HOlkodONpicjUAgHhHsIhyk4sz9W/jc+XxGlyNEwBgOoJFDLh3tu8Mkbe3VDBqAQAwFcEiBkwpztQ3ukYt6LUAAJiJYBEjunst3tpcoYO1jFoAAMxBsIgRU4cP0cXjukYt6LUAAJiEYBFDuq9r8ebmCh2qbTW5GgBAPCJYxJBpw4foou5Ri1XMfAoACD+CRYzp7rV4cxOjFgCA8CNYxJjpJUN04dgcdXoNPcsZIgCAMCNYxKD7unot3thUrrI6Ri0AAOFDsIhB00uyGLUAAJiCYBGjunst/mcjoxYAgPAhWMSoGSOydMEY36jF7z5k1AIAEB4BB4uKigp95zvfUXZ2tpKTkzVp0iRt2LAhFLVhkLqva/H6hnKVH2PUAgAQegEFi2PHjun8889XYmKi/vGPf2jHjh36r//6Lw0ZMiRU9WEQzhmRpfNGZ3eNWuw1uxwAQBxICGThxx9/XMXFxVq8eLH/sZEjRwa9KATPvZeO1ad7a/X6hjLddfFoFWelmF0SACCGBTRi8de//lUzZszQDTfcoLy8PE2dOlXPP/98n69xuVxqbGzscUP4lI7K1nmjs9XhMfSjlzeq1d1pdkkAgBgWULDYt2+fFi1apLFjx2rZsmW66667dM8992jJkiW9vmbhwoVyOp3+W3Fx8aCLRmAev/5sZafa9UVlo3722lZ5vYbZJQEAYpTFMIx+f8vY7XbNmDFDn376qf+xe+65R5999pnWrFlzyte4XC65XC7/742NjSouLlZDQ4MyMjIGUToC8dmBOt38/Fp1eAzdc+lY/fv/Gmd2SQCAKNLY2Cin03na7++ARiwKCgp05pln9njsjDPO0KFDh3p9jcPhUEZGRo8bwu+cEVn6j2snSZKeXrlb726tNLkiAEAsCihYnH/++dq5c2ePx3bt2qWSkpKgFoXQuGFGsX5w0ShJ0s9f36qtZfXmFgQAiDkBBYuf/vSnWrt2rf7jP/5De/bs0auvvqrnnntOCxYsCFV9CLL7r5igSybkydXp1Z1/2qDqhnazSwIAxJCAgsU555yjt956S0uXLtVZZ52lxx57TE899ZTmz58fqvoQZDarRf/3pikaNzRNNU0u3fmnDWpze8wuCwAQIwJq3gyG/jZ/ILQO1bZq7rMf61hrh648u0C/nTdVFovF7LIAABEqJM2biB3Ds1P0++9MV6LNovc+r9LTK5lPBAAweASLOFY6Klv/7zVnSZL+vxW79N7nVSZXBACIdgSLOPftc4br9gt8l2X/2etbtK28weSKAADRjGABPThngi4el6v2Dt+ZIjWNnCkCABgYggWUYLPqmZunakxemqob23XnnzaovYMzRQAAgSNYQJKUkZSoF26ZocyURG0tb9Av/udzhfmEIQBADCBYwK8kO1WL5k9XgtWid7dW6tlVnCkCAAgMwQI9zBqdrf9nru9Mkd/8c5fe386ZIgCA/iNY4CQ3lw7XreeNkCT99C9btb2CM0UAAP1DsMAp/Z8rz9CFY3PU1uHxnSnSxJkiAIDTI1jglBJsVv325mkalZuqqoZ2/eBPGzlTBABwWgQL9MqZnKgXbjlHzuREbSmr1wNvcKYIAKBvBAv0aWROqhbNnyab1aK3t1Tqdx/uNbskAEAEI1jgtM4bk6NHrp4oSfr1sp365xfVJlcEAIhUBAv0y3fPLdH3ZpVIku77yxbtqGw0uSIAQCQiWKDffvmtM3XBmBy1un1nihxpcpldEgAgwhAs0G8JNquevXmaRuakqqK+TT96eaNcnZwpAgA4jmCBgDhTEvXHW2YoIylBGw8e04NvbuNMEQCAH8ECARudm6Znu84UeXNThf7w0T6zSwIARAiCBQbkwrG5+uW3zpQkPf7+V1q+47DJFQEAIgHBAgP2vVklml86XIYh3fvfm7XxYJ3ZJQEATEawwIBZLBY9cvVEXTjWd6bILS9+pk2HjpldFgDARAQLDEqizarnvjtD547KUrOrU7e8sF5by+rNLgsAYBKCBQYt2W7Ti7eeo5kjs9Tk6tR3X1inbeVMtQ4A8YhggaBIsSdo8a3naEbJEDW2d+o7L6zT9grCBQDEG4IFgibVkaCXbpupacMz1dDWoe+8sI5LfwNAnCFYIKjSHAlacttMTSnOVH1rh+b/ca2+qiZcAEC8IFgg6NKTErXktpk6u8ipY60dmv/8Ou0+3GR2WQCAMCBYICScyYn6822lOmtYhmpb3Jr3/DrtqWk2uywAQIgRLBAyzpREvXx7qc4syNDRZpfmPb9We48QLgAglhEsEFKZKXa9fEepJuSn60iTSzc/v1b7j7aYXRYAIEQIFgi5rFS7XrmjVOOGpulwo0vznlurg7WECwCIRQQLhEV2mkOv3HGuxuSlqbqxXfOeW6uyulazywIABBnBAmGTm+7Qq3eWalRuqiob2nXTc2tVfoxwAQCxhGCBsMpLT9LSO8/VyJxUVdS3ad7za1VZ32Z2WQCAICFYIOyGZvjCRUl2isrqfOGiqoFwAQCxgGABU+Q7feGiOCtZB2tbdfPz63S4sd3ssgAAg0SwgGkKM5O19M5zVTQkWfuPtmje82tV00S4AIBoRrCAqYqGpGjpnedqWGay9h1p0c3Pr9ORJpfZZQEABohgAdMVZ/nCRYEzSXtqmjX/j2tV20y4AIBoRLBARBie7QsXQzMc2nW4WfP/uE51LW6zywIABIhggYgxIidVS+88V3npDn1V3aT5f1yn+lbCBQBEE4IFIsqo3DS9eue5yklz6MuqRn3nhXVqaO0wuywAQD8RLBBxxuSlaemdpcpOtWt7RaO+++I6NbQRLgAgGhAsEJHGDk3Xq3eeq6xUuz4vb9DVv/1Y726tlNdrmF0aAKAPBAtErPH56XrljlLlpTt0sLZVP1m6WXOf/UQf7z5qdmkAgF5YDMMI638BGxsb5XQ61dDQoIyMjHC+NaJUi6tTf/zXfj330V61uD2SpAvH5uj+KyborGFOk6sDgPjQ3+9vggWixtFml377wR69su6gOjy+v7bfOrtAP79svEbkpJpcHQDENoIFYlZZXaueXL5Lb2+pkGFICVaL5s0crp9cOkZ56UlmlwcAMYlggZi3o7JRTyz7Sh/uPCJJSrHbdMcFI3XnRaOUnpRocnUAEFsIFogba/bW6j/f/0pby+olSVmpdt39b2M0/9zhciTYzC0OAGIEwQJxxTAMLfuiWk+8v1P7jrZIkoqGJOtnl43T3MnDZLVaTK4QAKIbwQJxqdPj1WsbyvXUil2q6ZoldUJ+uu6fM0HfGJcri4WAAQADQbBAXGtze/TiJ/v1+9V71dTeKUkqHZmlB+ZM0NThQ0yuDgCiD8ECkHSsxa1Fq/fqpU8PyN3plSRdMTFfv7hivEbnpplcHQBED4IFcIKK+jY9tXyX3thULq8h2awW3TijSPdeOk75Tk5RBYDTIVgAp7DrcJOeeH+nVnx5WJKUlGjV988fqR9eNEqZKXaTqwOAyNXf7++A5gp55JFHZLFYetwmTJgw6GKBcBk3NF1/vGWG/udHszSjZIjaO7xa9OFeXfD4Kj3x/leqa3GbXSIARLWEQF8wceJErVix4vgKEgJeBWC6GSOy9PqPZmnllzX6zT936qvqJv3uw71a/MkBfXdWie64cCRX8QSAAQg4FSQkJCg/Pz8UtQBhZbFYNPvMobpkQp5WfHlYz3ywR9sqGvTcR/u05NMDmjdzuH508Wh6MAAgAAFPm757924VFhZq1KhRmj9/vg4dOtTn8i6XS42NjT1uQCSxWi26bGK+/nr3+Vr8/XM0dXimXJ1evfTpAV30xCr9n7e3qfxYq9llAkBUCKh58x//+Ieam5s1fvx4VVVV6dFHH1VFRYW2b9+u9PT0U77mkUce0aOPPnrS4zRvIlIZhqFP9tTq6ZW7tf5AnSTfRGfXTyvSj/9ttEqymUkVQPwJy1kh9fX1Kikp0ZNPPqnbb7/9lMu4XC65XK4ehRUXFxMsEBXW7qvVMx/s1id7aiX5TlOdO6VQd//bGI3iOhgA4kh/g8WgOi8zMzM1btw47dmzp9dlHA6HHA7HYN4GMM25o7J17qhsbTxYp6dX7tHqXUf05qYKvb25Qt86u1B3XzJG44aeerQOAOJRwD0WJ2pubtbevXtVUFAQrHqAiDS9JEtLbpupdxacr9ln5MlrSH/dWqnLn/pIP35lo3ZU0jsEAFKAh0J+/vOf66qrrlJJSYkqKyv18MMPa8uWLdqxY4dyc3P7tQ4ukIVY8EVlg377wR79Y3u1/7HZZwzVPZeO0dlFmeYVBgAhEpJDIeXl5Zo3b55qa2uVm5urCy64QGvXru13qABixcRCpxZ9Z7p2Vjfpt6v26G+fV2rFl4e14svD+sb4XP3kkrGaXsJkZwDiD5f0BoJgT02zfrdqj97ZWimP1/eRumBMjn5yyRiVjso2uToAGDzmCgFMcLC2Rb9btVdvbCpXZ1fAmDkiSzfNLNblE/OV6uBKtQCiE8ECMFFZXat+v3qvXt9QLrfHN117it2mKybm67ppRZo1Ols2q8XkKgGg/wgWQASoamjT6xvK9eamch2oPX71zvyMJF0zdZiumzaM01UBRAWCBRBBDMPQpkP1enNTuf72eZUa2jr8z501LEPXTS3S1VMKlZPGNV8ARCaCBRChXJ0erfqqRm9sqtCqr2r8vRg2q0XfGJera6cN0+wzhiop0WZypQBwHMECiAJ1LW69u7VSb26u0Nayev/j6UkJ+tbZBbpuWpFmlAyRxUI/BgBzESyAKLOnpllvbS7XW5sqVNnQ7n+8OCtZ104t0nVTh2lEDhOgATAHwQKIUl6voXX76/TmpnL9fVuVWtwe/3PTS4boumnD9K1JhXKmJJpYJYB4Q7AAYkCb26N/7qjWG5sq9PHuI+pqx5DdZtWlZ+TpumlFunhcruwJg5r2BwBOi2ABxJiaxna9s6VSb2wq11fVTf7HU+02TR+RpdKRWTp3VJYmDcskaAAIOoIFEMN2VDbqzU3lemdrpY40uXo8l5xo07SSTJWOzFbpyCxNLs7kDBMAg0awAOKAx2voq+pGrdtXp3X7a7V+f52OtXb0WMaeYNXU4kyVjsrWuSOzNHX4ECXbCRoAAkOwAOKQ12tod02z1u2v1br9dVq3r05Hm3uOaCTaLJpclKmZI7NUOipbM0qGMIcJgNMiWACQYRjad7TFP6Kxbl+dqhvbeyxjs1p01jCnzh2ZpdJRWZoxIksZSZxxAqAnggWAkxiGoUN1rf7RjHX7a1V+rK3HMlaLdGZhhr9Ho3RUtpzJBA0g3hEsAPRLRX2b1u2r9QeNEydLk3wjGtOGZ+ricbm6eFyeJhZmyMrMrEDcIVgAGJDDje1dIxq1WrOvVvuOtPR4PjvVrovG5ericbm6cGyOspk4DYgLBAsAQVF+rFUf7Tqq1btq9MmeWjW7Ov3PWSzSpGFOXTwuVxeNy9XU4kwl2LiGBhCLCBYAgq7D49Wmg8e0etcRrd51RF9UNvZ4Pj0pQReMyfEdNhmfqwJnskmVAgg2ggWAkKtpate/dh3V6l1H9K/dR066hsa4oWn+3oxzRg6RI4HrZwDRimABIKw8XkPbKhq0eucRrd5Voy1l9f65TSTfFUFnjc7uChq5zNQKRBmCBQBT1be69fGeo11B44hqvnbp8ZLsFF04NkdnFjg1Ji9NY/LSlJVqN6laAKdDsAAQMQzD0FfVTb7ejJ1HtOFgnTo8J//Tk5Vq15jcNI3uChqjc1M1Ji9Nhc5kTnEFTEawABCxml2dWrO3Vuv21Wp3TbP21DSror6t1+WTE20anZeqMblp/tGN0blpKslOZSZXIEwIFgCiSqu7U/uOtGjvEV/Q6L4dqG055eiGJCVYLRqendIjcHSHDuY/AYKLYAEgJnR4vDpU1+oPGnuPNGtv188tbk+vrytwJml0bppG5KRoRHaqSrJTNSI7RcVZKUwjDwwAwQJATDMMQ9WN7T1GN3yjHS0nzeh6IotFKnQmqyQ7xR82SrJTNSInRSVZqUwpD/SCYAEgbtW3un0jG0dadKi2VftrW3SwtkUHjrb2uHLoqeRnJKkku2uUwz/a4QsfaRxeQRwjWADA1xiGoboWtw7UtvqCRm2rDhz1hY79R1vU2N536MhNdxwf4chOUYEzWVlpdmWn2pWd5lB2qp3DLIhZBAsACFB96wmh46jv3jfa0aq6Fne/1pFityk7za6sVF/QyEq1K7srfHQ/5nveruxUB4deEDX6+/3NuB4AdMlMsWtKil1TijNPeq6hrUOHalt1oLZ7hKNVNU3tqm12q67FrdoWlzo8hlrdHrXWtamsrvfTZ0+UYrd1hYzuEHI8fBQN8R2KGZGTohQ7/1wjOvA3FQD6wZmcqElFTk0qcp7yecMw1OTqVF2zW7UtbtU2u7oCh7srfLhO+Nl3c3u8viDiblP5sb6DyNAMh0Zkp2pkju82out+OGe5IMIQLAAgCCwWizKSEpWRlNiveVBOF0SONrt0qK5V+4+2qKGtQ4cbXTrc6NK6/XVfe1/fWS7dp9WOzEntGuXwhQ4uIIZwI1gAgAkCCSLHWtzaX9uiA0d9t/1dTacHjraoydWpivo2VdS36ZM9tT1eZ7XIdzglJ1Ujs333vp9TVTQkWQk2QgeCj2ABABFuSKpdQ1LtmjZ8SI/HDcNQbYvbFzaOtuhAV9Np98+tbo8O1bXqUF2rPvraOm1Wi4amO1SQmawCZ5IKu+4LnMkqzPTd56TZZbEwRwsCQ7AAgChlsViUk+ZQTppDM0Zk9XjOMAzVNLl8IeNoywkjHr4GVFenV5UN7apsaO91/XabVfnOpJ7BIzNZhScEEGdyIuEDPRAsACAGWSwWDc1I0tCMJJ07KrvHc16vL3RUNrSpqr5dVQ1tquy+b2hXVX2bjjS75O66nPqhutZe3yfFblO+M0mFzp7BIzfdoVRHgtIcCUqx25TmSFCqI0HJiTZmqo1xBAsAiDNWq0X5ziTlO5Ok4adext3p1eHGdlU1fC14dN1XNbSrrsWtVrdH+460aN+Rln6/f6rdppQTQkeqI0Gp/ntfAEl19Hw8xd61vMMXUjJTEpWd6pCNkBJxCBYAgJPYE6wqzvJN2tab9g6PL3jUHx/pqOwKIrXNbrW4O9Xi6lSry6MWd6e8XZdjbHF71OL26EhT73O69IfVImWnOZSb5lBehu8+N92hvHSHctOTTvjZwWy3YcSfNABgQJISbf7rapyOYRhq7/Cq2dWpVndn173Hd+/yqMXV6Q8iLe6u37/2ePfyLa5O1bd1yGtIR5pcOtLk0o6qvt8/1W5Tbnp38Ejy/+y/dYUTRkEGj2ABAAg5i8WiZLut6xLmjkGvr9PjVV2LWzVNLh1pdulIY9d9k0s1Te3+wFHT5FJr1whJS22rDtT23i8i+UZBslIdSnXY5EiwKinRpqQEmxyJXT8n2pTU/fgJjzkSrHL0eO6E5xOO/9y9XKLNokSbVQlWS8w1vxIsAABRJ8FmVV5GkvIykk67bIur0x8yfIGj3f+z/7Fml2qbXfIa0tFml442h2EjuiRYu0KGzSJ7132C1Sp7gi94JNisstt89ycGkkSb1f+6xB7PWXXf/xqrjKTE8G3EidtjyrsCABAmqV1npJzuQmQer6HaFpeONrnV1tGp9g6v2js8x+87j//s6vTK1eE5/nyn52vL9v7813V6DXV6PVJH8Lb5rm+Mlk6fuUKCYAEAgHwXDctLT1Jeeui+kQ3DkNvjVafHUIfHqw6PoU6vVx2dhjq8XnV8/TmPVx1eQx2dXt9yXc91errX41Wn9/g6Oz1euT2GUh3mzR9DsAAAIEwsFoscCTbF8kkqXCgeAAAEDcECAAAEDcECAAAEDcECAAAEDcECAAAEDcECAAAEDcECAAAEDcECAAAEDcECAAAEDcECAAAEDcECAAAEDcECAAAEDcECAAAETdjnVzMMQ5LU2NgY7rcGAAAD1P293f093puwB4umpiZJUnFxcbjfGgAADFJTU5OcTmevz1uM00WPIPN6vaqsrFR6erosFks43zqsGhsbVVxcrLKyMmVkZJhdTkixrbErnraXbY1d8bS9odxWwzDU1NSkwsJCWa29d1KEfcTCarWqqKgo3G9rmoyMjJj/i9yNbY1d8bS9bGvsiqftDdW29jVS0Y3mTQAAEDQECwAAEDQEixBxOBx6+OGH5XA4zC4l5NjW2BVP28u2xq542t5I2NawN28CAIDYxYgFAAAIGoIFAAAIGoIFAAAIGoIFAAAIGoLFACxcuFDnnHOO0tPTlZeXp2uuuUY7d+7s8zUvvfSSLBZLj1tSUlKYKh64Rx555KS6J0yY0OdrXn/9dU2YMEFJSUmaNGmS/v73v4ep2sEbMWLESdtrsVi0YMGCUy4fTfv1o48+0lVXXaXCwkJZLBa9/fbbPZ43DEO//OUvVVBQoOTkZM2ePVu7d+8+7XqfffZZjRgxQklJSSotLdX69etDtAX919e2dnR06P7779ekSZOUmpqqwsJCfe9731NlZWWf6xzIZyFcTrdvb7311pNqv+KKK0673mjbt5JO+fm1WCz69a9/3es6I3Xf9ue7pr29XQsWLFB2drbS0tJ0/fXX6/Dhw32ud6Cf9f4iWAzA6tWrtWDBAq1du1bLly9XR0eHLrvsMrW0tPT5uoyMDFVVVflvBw8eDFPFgzNx4sQedX/88ce9Lvvpp59q3rx5uv3227V582Zdc801uuaaa7R9+/YwVjxwn332WY9tXb58uSTphhtu6PU10bJfW1paNHnyZD377LOnfP6JJ57Q008/rd///vdat26dUlNTdfnll6u9vb3Xdf7lL3/Rv//7v+vhhx/Wpk2bNHnyZF1++eWqqakJ1Wb0S1/b2traqk2bNumhhx7Spk2b9Oabb2rnzp26+uqrT7veQD4L4XS6fStJV1xxRY/aly5d2uc6o3HfSuqxjVVVVXrxxRdlsVh0/fXX97neSNy3/fmu+elPf6p3331Xr7/+ulavXq3Kykpdd911fa53IJ/1gBgYtJqaGkOSsXr16l6XWbx4seF0OsNXVJA8/PDDxuTJk/u9/I033mhceeWVPR4rLS01fvjDHwa5svC49957jdGjRxter/eUz0frfpVkvPXWW/7fvV6vkZ+fb/z617/2P1ZfX284HA5j6dKlva5n5syZxoIFC/y/ezweo7Cw0Fi4cGFI6h6Ir2/rqaxfv96QZBw8eLDXZQL9LJjlVNt7yy23GHPnzg1oPbGyb+fOnWtccsklfS4TLfv269819fX1RmJiovH666/7l/nyyy8NScaaNWtOuY6BftYDwYhFEDQ0NEiSsrKy+lyuublZJSUlKi4u1ty5c/XFF1+Eo7xB2717twoLCzVq1CjNnz9fhw4d6nXZNWvWaPbs2T0eu/zyy7VmzZpQlxl0brdbL7/8sm677bY+J8yL1v16ov3796u6urrHvnM6nSotLe1137ndbm3cuLHHa6xWq2bPnh11+7uhoUEWi0WZmZl9LhfIZyHSfPjhh8rLy9P48eN11113qba2ttdlY2XfHj58WO+9955uv/320y4bDfv26981GzduVEdHR4/9NGHCBA0fPrzX/TSQz3qgCBaD5PV6dd999+n888/XWWed1ety48eP14svvqh33nlHL7/8srxer8477zyVl5eHsdrAlZaW6qWXXtL777+vRYsWaf/+/brwwgvV1NR0yuWrq6s1dOjQHo8NHTpU1dXV4Sg3qN5++23V19fr1ltv7XWZaN2vX9e9fwLZd0ePHpXH44n6/d3e3q77779f8+bN63PSpkA/C5Hkiiuu0J/+9CetXLlSjz/+uFavXq05c+bI4/GccvlY2bdLlixRenr6aQ8NRMO+PdV3TXV1tex2+0mBuK/9NJDPeqDCPrtprFmwYIG2b99+2uNxs2bN0qxZs/y/n3feeTrjjDP0hz/8QY899lioyxywOXPm+H8+++yzVVpaqpKSEr322mv9+l9ANHvhhRc0Z84cFRYW9rpMtO5X+HR0dOjGG2+UYRhatGhRn8tG82fhpptu8v88adIknX322Ro9erQ+/PBDXXrppSZWFlovvvii5s+ff9qG6mjYt/39rokEjFgMwt13362//e1vWrVqVcBTwScmJmrq1Knas2dPiKoLjczMTI0bN67XuvPz80/qSD58+LDy8/PDUV7QHDx4UCtWrNAdd9wR0Ouidb92759A9l1OTo5sNlvU7u/uUHHw4EEtX7484CmmT/dZiGSjRo1STk5Or7VH+76VpH/961/auXNnwJ9hKfL2bW/fNfn5+XK73aqvr++xfF/7aSCf9UARLAbAMAzdfffdeuutt/TBBx9o5MiRAa/D4/Fo27ZtKigoCEGFodPc3Ky9e/f2WvesWbO0cuXKHo8tX768x//qo8HixYuVl5enK6+8MqDXRet+HTlypPLz83vsu8bGRq1bt67XfWe32zV9+vQer/F6vVq5cmXE7+/uULF7926tWLFC2dnZAa/jdJ+FSFZeXq7a2tpea4/mfdvthRde0PTp0zV58uSAXxsp+/Z03zXTp09XYmJij/20c+dOHTp0qNf9NJDP+kAKR4Duuusuw+l0Gh9++KFRVVXlv7W2tvqX+e53v2s88MAD/t8fffRRY9myZcbevXuNjRs3GjfddJORlJRkfPHFF2ZsQr/97Gc/Mz788ENj//79xieffGLMnj3byMnJMWpqagzDOHk7P/nkEyMhIcH4zW9+Y3z55ZfGww8/bCQmJhrbtm0zaxMC5vF4jOHDhxv333//Sc9F835tamoyNm/ebGzevNmQZDz55JPG5s2b/WdC/Od//qeRmZlpvPPOO8bnn39uzJ071xg5cqTR1tbmX8cll1xiPPPMM/7f//u//9twOBzGSy+9ZOzYscP4wQ9+YGRmZhrV1dVh374T9bWtbrfbuPrqq42ioiJjy5YtPT7DLpfLv46vb+vpPgtm6mt7m5qajJ///OfGmjVrjP379xsrVqwwpk2bZowdO9Zob2/3ryMW9m23hoYGIyUlxVi0aNEp1xEt+7Y/3zU/+tGPjOHDhxsffPCBsWHDBmPWrFnGrFmzeqxn/Pjxxptvvun/vT+f9cEgWAyApFPeFi9e7F/m4osvNm655Rb/7/fdd58xfPhww263G0OHDjW++c1vGps2bQp/8QH69re/bRQUFBh2u90YNmyY8e1vf9vYs2eP//mvb6dhGMZrr71mjBs3zrDb7cbEiRON9957L8xVD86yZcsMScbOnTtPei6a9+uqVatO+fe2e3u8Xq/x0EMPGUOHDjUcDodx6aWXnvRnUFJSYjz88MM9HnvmmWf8fwYzZ8401q5dG6Yt6l1f27p///5eP8OrVq3yr+Pr23q6z4KZ+tre1tZW47LLLjNyc3ONxMREo6SkxLjzzjtPCgixsG+7/eEPfzCSk5ON+vr6U64jWvZtf75r2trajB//+MfGkCFDjJSUFOPaa681qqqqTlrPia/pz2d9MJg2HQAABA09FgAAIGgIFgAAIGgIFgAAIGgIFgAAIGgIFgAAIGgIFgAAIGgIFgAAIGgIFgAAIGgIFgAAIGgIFgAAIGgIFgAAIGgIFgAAIGj+f/zr9wSaB+2sAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "VwC16gOadE62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_5 (TimeDis  (None, None, 65)         0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " gru_11 (GRU)                (None, None, 40)          12840     \n",
            "                                                                 \n",
            " gru_12 (GRU)                (None, None, 40)          9840      \n",
            "                                                                 \n",
            " gru_13 (GRU)                (None, None, 40)          9840      \n",
            "                                                                 \n",
            " gru_14 (GRU)                (None, None, 40)          9840      \n",
            "                                                                 \n",
            " gru_15 (GRU)                (None, None, 40)          9840      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, None, 65)          2665      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,865\n",
            "Trainable params: 54,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model3 = Sequential()\n",
        "\n",
        "model3.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model3.add(GRU(40, return_sequences=True,))\n",
        "model3.add(GRU(40, return_sequences=True,))\n",
        "model3.add(GRU(40, return_sequences=True,))\n",
        "model3.add(GRU(40, return_sequences=True,))\n",
        "model3.add(GRU(40, return_sequences=True,))\n",
        "model3.add(Dense(vocab_size, activation='softmax'))\n",
        "model3.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "deRTkYBZdQMB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 3.0670\n",
            " mean perplexity: 18.579493227299245 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 45s 191ms/step - loss: 3.0670\n",
            "Epoch 2/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.5789\n",
            " mean perplexity: 11.30130107786873 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 37s 180ms/step - loss: 2.5789\n",
            "Epoch 3/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.3482\n",
            " mean perplexity: 10.055080524027218 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 38s 186ms/step - loss: 2.3482\n",
            "Epoch 4/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.2511\n",
            " mean perplexity: 9.305491774576717 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 38s 186ms/step - loss: 2.2511\n",
            "Epoch 5/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.1847\n",
            " mean perplexity: 8.75343361109786 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 2.1847\n",
            "Epoch 6/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.1294\n",
            " mean perplexity: 8.382923071071634 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 37s 180ms/step - loss: 2.1294\n",
            "Epoch 7/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.0827\n",
            " mean perplexity: 8.27095781697519 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 2.0827\n",
            "Epoch 8/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.0449\n",
            " mean perplexity: 7.954799470536818 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 37s 181ms/step - loss: 2.0449\n",
            "Epoch 9/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 2.0128\n",
            " mean perplexity: 7.77611059594365 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 37s 182ms/step - loss: 2.0128\n",
            "Epoch 10/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.9833\n",
            " mean perplexity: 7.56864448488455 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 37s 179ms/step - loss: 1.9833\n",
            "Epoch 11/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.9559\n",
            " mean perplexity: 7.416958323199366 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 38s 188ms/step - loss: 1.9559\n",
            "Epoch 12/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.9293\n",
            " mean perplexity: 7.292804186260267 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 1.9293\n",
            "Epoch 13/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.9027\n",
            " mean perplexity: 7.185393539563165 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 37s 182ms/step - loss: 1.9027\n",
            "Epoch 14/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.8772\n",
            " mean perplexity: 6.897955787637963 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 39s 189ms/step - loss: 1.8772\n",
            "Epoch 15/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.8527\n",
            " mean perplexity: 6.766035193904627 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 1.8527\n",
            "Epoch 16/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.8301\n",
            " mean perplexity: 6.692481020115681 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 1.8301\n",
            "Epoch 17/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.8099\n",
            " mean perplexity: 6.50414745553233 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 39s 190ms/step - loss: 1.8099\n",
            "Epoch 18/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7908\n",
            " mean perplexity: 6.437474122566175 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 36s 176ms/step - loss: 1.7908\n",
            "Epoch 19/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7727\n",
            " mean perplexity: 6.40163631757194 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 1.7727\n",
            "Epoch 20/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.7564\n",
            " mean perplexity: 6.231876692497312 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 37s 181ms/step - loss: 1.7564\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model3.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl,5,'my_model_GRU2')], batch_size=2048)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los resultados despues de entrar a cada modelo por solamente 20 epocas.\n",
        "Cabe aclarar que en el caso de GRU5 se eligio utilizar dado que las topologias GRU y LSTM se asemejan a la idea de las redes residuales, que utilizan skip connections para evitar que se degrade el gradiente. Por lo tanto serian especialmente utiles en redes con muchas capas. Y como las redes residuales, permiten entrenar mucho mas. Sin embargo al solo entrenar 20 epocas, no le podemos sacar el provecho."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Modelo       | Parameters | Perplexity |\n",
        "|--------------|------------|------------|\n",
        "| Elman        | 66.265     | 4.85       |\n",
        "| LSTM         | 225.865    | 4.47       |\n",
        "| GRU          | 173.265    | 4.28       |\n",
        "| GRU, 5 CAPAS | 54.865     | 6.23       |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "### Predicción del próximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "IBvKHFPmzpy2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mlserver 1.3.5 requires fastapi!=0.89.0,<=0.89.1,>=0.88.0, but you have fastapi 0.111.1 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "# Se puede usar gradio para probar el modelo\n",
        "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
        "# https://gradio.app/\n",
        "\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "HNyBykvhzs7-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Gonzalo\\miniconda3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 206ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "JoFqRC5pxzqS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "el retrato de la puerta de la puerta de \n",
            "el retrato de la mano en el pecado en la\n",
            "el retrato de la mesa, y la mesa y la pu\n",
            "el retrato de la marande de la marande d\n"
          ]
        }
      ],
      "source": [
        "input_text='el retrato'\n",
        "\n",
        "\n",
        "print(generate_seq(model, input_text, max_length=max_context_size, n_words=30)) # Elman\n",
        "print(generate_seq(model1, input_text, max_length=max_context_size, n_words=30)) #LSTM\n",
        "print(generate_seq(model2, input_text, max_length=max_context_size, n_words=30)) # GRU\n",
        "print(generate_seq(model3, input_text, max_length=max_context_size, n_words=30)) # GRU5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "GeLqAoOYW1Hm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Elman ---\n",
            "dorian gray estaba en el mundo en el mundo en el mundo en el mundo e\n",
            "dorian gray estaba en el mundo en el mundo en el mundo en la cabeza \n",
            "dorian gray estaba en el mundo en el mundo en el retrato de la vida \n",
            "dorian gray estaba en el mundo en el mundo en el mundo en el mundo. \n",
            "dorian gray estaba en el mundo en el mundo en el mundo en el pintor \n",
            "dorian gray estaba en el mundo en el mundo en el mundo en el mundo, \n",
            "dorian gray estaba en el mundo en el mundo en el mundo en la cabeza.\n",
            "dorian gray estaba en el mundo en el mundo en el mundo en el mundo a\n",
            "dorian gray estaba en el mundo en el mundo en el mundo en el mundo l\n",
            "dorian gray estaba en el mundo en el mundo en el mundo en el mundo s\n",
            "--- LSTM ---\n",
            "dorian gray estaba en el cuadro de las mujeres que se había encontra\n",
            "dorian gray estaba en el cuadro de las mujeres que había algo en el \n",
            "dorian gray estaba en el cuadro de las mujeres que se había sido una\n",
            "dorian gray estaba en el cuadro de las mujeres que había algo en la \n",
            "dorian gray estaba en el cuadro de las mujeres que se había sido un \n",
            "dorian gray estaba en el cuadro de las mujeres que se había sido el \n",
            "dorian gray estaba en el cuadro de las mujeres que se había sido en \n",
            "dorian gray estaba en el cuadro de las mujeres que había algo que se\n",
            "dorian gray estaba en el cuadro de las mujeres que había sido una ma\n",
            "dorian gray estaba en el cuadro de las mujeres que había algo que el\n",
            "--- GRU ---\n",
            "dorian gray estaba en una persona de las mujeres de los sentidos de \n",
            "dorian gray estaba en una persona de las mujeres de las mujeres de l\n",
            "dorian gray estaba en una persona de las mujeres de las mujeres de s\n",
            "dorian gray estaba en una persona de las mujeres de las mujeres del \n",
            "dorian gray estaba en una persona de las mujeres de los sentidos en \n",
            "dorian gray estaba en una persona de las mujeres de las cosas que se\n",
            "dorian gray estaba en una persona de las mujeres de la cabeza de la \n",
            "dorian gray estaba en una persona de las mujeres de las mujeres de c\n",
            "dorian gray estaba en una persona de las mujeres de las mujeres de \n",
            "dorian gray estaba en una persona de las mujeres de las mujeres \n",
            "de\n",
            "--- GRU5 ---\n",
            "dorian gray estaba que lo que había que lo que lo que lo que lo que \n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo que se \n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo que no \n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo que lo \n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo que la \n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo que es \n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo que te \n",
            "dorian gray estaba que lo que había que lo que lo que lo que lo habí\n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo había e\n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo había d\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search\n",
        "print('--- Elman ---')\n",
        "beam= beam_search(model,num_beams=10,num_words=50,input=\"dorian gray estaba\");\n",
        "for item in range(10):\n",
        "    print(decode(beam[item]))\n",
        "print('--- LSTM ---')\n",
        "beam= beam_search(model1,num_beams=10,num_words=50,input=\"dorian gray estaba\");\n",
        "for item in range(10):\n",
        "    print(decode(beam[item]))\n",
        "print('--- GRU ---')\n",
        "beam= beam_search(model2,num_beams=10,num_words=50,input=\"dorian gray estaba\");\n",
        "for item in range(10):\n",
        "    print(decode(beam[item]))\n",
        "print('--- GRU5 ---')\n",
        "beam= beam_search(model3,num_beams=10,num_words=50,input=\"dorian gray estaba\");\n",
        "for item in range(10):\n",
        "    print(decode(beam[item]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Elman ---\n",
            "dorian gray estaba en el mundo en el mundo en el mundo en el mundo e\n",
            "dorian gray estaba en el mundo en el mundo en el mundo en la cabeza \n",
            "dorian gray estaba en el mundo en el mundo en el retrato de la vida \n",
            "dorian gray estaba en el mundo en el mundo en el mundo en el mundo. \n",
            "dorian gray estaba en el mundo en el mundo en el mundo en el pintor \n",
            "dorian gray estaba en el mundo en el mundo en el mundo en el mundo, \n",
            "dorian gray estaba en el mundo en el mundo en el mundo en la cabeza.\n",
            "dorian gray estaba en el mundo en el mundo en el mundo en el mundo a\n",
            "dorian gray estaba en el mundo en el mundo en el mundo en el mundo l\n",
            "dorian gray estaba en el mundo en el mundo en el mundo en el mundo s\n",
            "--- LSTM ---\n",
            "dorian gray estaba en el cuadro de las mujeres que se había encontra\n",
            "dorian gray estaba en el cuadro de las mujeres que había algo en el \n",
            "dorian gray estaba en el cuadro de las mujeres que se había sido una\n",
            "dorian gray estaba en el cuadro de las mujeres que había algo en la \n",
            "dorian gray estaba en el cuadro de las mujeres que se había sido un \n",
            "dorian gray estaba en el cuadro de las mujeres que se había sido el \n",
            "dorian gray estaba en el cuadro de las mujeres que se había sido en \n",
            "dorian gray estaba en el cuadro de las mujeres que había algo que se\n",
            "dorian gray estaba en el cuadro de las mujeres que había sido una ma\n",
            "dorian gray estaba en el cuadro de las mujeres que había algo que el\n",
            "--- GRU ---\n",
            "dorian gray estaba en una persona de las mujeres de los sentidos de \n",
            "dorian gray estaba en una persona de las mujeres de las mujeres de l\n",
            "dorian gray estaba en una persona de las mujeres de las mujeres de s\n",
            "dorian gray estaba en una persona de las mujeres de las mujeres del \n",
            "dorian gray estaba en una persona de las mujeres de los sentidos en \n",
            "dorian gray estaba en una persona de las mujeres de las cosas que se\n",
            "dorian gray estaba en una persona de las mujeres de la cabeza de la \n",
            "dorian gray estaba en una persona de las mujeres de las mujeres de c\n",
            "dorian gray estaba en una persona de las mujeres de las mujeres de \n",
            "dorian gray estaba en una persona de las mujeres de las mujeres \n",
            "de\n",
            "--- GRU5 ---\n",
            "dorian gray estaba que lo que había que lo que lo que lo que lo que \n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo que se \n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo que no \n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo que lo \n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo que la \n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo que es \n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo que te \n",
            "dorian gray estaba que lo que había que lo que lo que lo que lo habí\n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo había e\n",
            "dorian gray estaba que lo que lo que lo que lo que lo que lo había d\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search con temperatura 10\n",
        "print('--- Elman ---')\n",
        "beam= beam_search(model,num_beams=10,num_words=50,input=\"dorian gray estaba\",temp=10);\n",
        "for item in range(10):\n",
        "    print(decode(beam[item]))\n",
        "print('--- LSTM ---')\n",
        "beam= beam_search(model1,num_beams=10,num_words=50,input=\"dorian gray estaba\",temp=10);\n",
        "for item in range(10):\n",
        "    print(decode(beam[item]))\n",
        "print('--- GRU ---')\n",
        "beam= beam_search(model2,num_beams=10,num_words=50,input=\"dorian gray estaba\",temp=10);\n",
        "for item in range(10):\n",
        "    print(decode(beam[item]))\n",
        "print('--- GRU5 ---')\n",
        "beam= beam_search(model3,num_beams=10,num_words=50,input=\"dorian gray estaba\",temp=10);\n",
        "for item in range(10):\n",
        "    print(decode(beam[item]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A ojo desnudo las oraciones mas humanas vienen de LSTM Y GRU que son los dos modelos de minima perplexity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para verificar y explorar un poco mas, propongo entrenar 20 epocas mas el mejor modelo, GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3832\n",
            " mean perplexity: 4.258897235967298 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 121s 591ms/step - loss: 1.3832\n",
            "Epoch 2/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3784\n",
            " mean perplexity: 4.233474987545185 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 124s 604ms/step - loss: 1.3784\n",
            "Epoch 3/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3739\n",
            " mean perplexity: 4.2340882880780395 \n",
            "\n",
            "205/205 [==============================] - 117s 572ms/step - loss: 1.3739\n",
            "Epoch 4/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3700\n",
            " mean perplexity: 4.234792194326168 \n",
            "\n",
            "205/205 [==============================] - 115s 562ms/step - loss: 1.3700\n",
            "Epoch 5/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3662\n",
            " mean perplexity: 4.227513137912837 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 120s 586ms/step - loss: 1.3662\n",
            "Epoch 6/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3627\n",
            " mean perplexity: 4.215819880061064 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 118s 574ms/step - loss: 1.3627\n",
            "Epoch 7/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3595\n",
            " mean perplexity: 4.201654175042858 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 117s 571ms/step - loss: 1.3595\n",
            "Epoch 8/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3563\n",
            " mean perplexity: 4.211527819363268 \n",
            "\n",
            "205/205 [==============================] - 116s 565ms/step - loss: 1.3563\n",
            "Epoch 9/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3535\n",
            " mean perplexity: 4.19811999954962 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 117s 571ms/step - loss: 1.3535\n",
            "Epoch 10/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3509\n",
            " mean perplexity: 4.182627813236662 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 120s 584ms/step - loss: 1.3509\n",
            "Epoch 11/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3483\n",
            " mean perplexity: 4.195216977082096 \n",
            "\n",
            "205/205 [==============================] - 117s 571ms/step - loss: 1.3483\n",
            "Epoch 12/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3459\n",
            " mean perplexity: 4.1753532335427925 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 118s 578ms/step - loss: 1.3459\n",
            "Epoch 13/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3438\n",
            " mean perplexity: 4.18966756654183 \n",
            "\n",
            "205/205 [==============================] - 115s 561ms/step - loss: 1.3438\n",
            "Epoch 14/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3417\n",
            " mean perplexity: 4.191606138060005 \n",
            "\n",
            "205/205 [==============================] - 115s 562ms/step - loss: 1.3417\n",
            "Epoch 15/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3396\n",
            " mean perplexity: 4.18762665598782 \n",
            "\n",
            "205/205 [==============================] - 114s 557ms/step - loss: 1.3396\n",
            "Epoch 16/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3376\n",
            " mean perplexity: 4.177427859228957 \n",
            "\n",
            "205/205 [==============================] - 119s 583ms/step - loss: 1.3376\n",
            "Epoch 17/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3356\n",
            " mean perplexity: 4.17243857544966 \n",
            "\n",
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model_GRU\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new model!\n",
            "205/205 [==============================] - 117s 571ms/step - loss: 1.3356\n",
            "Epoch 18/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3340\n",
            " mean perplexity: 4.209343747903034 \n",
            "\n",
            "205/205 [==============================] - 120s 583ms/step - loss: 1.3340\n",
            "Epoch 19/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3322\n",
            " mean perplexity: 4.191259932981212 \n",
            "\n",
            "205/205 [==============================] - 116s 565ms/step - loss: 1.3322\n",
            "Epoch 20/20\n",
            "205/205 [==============================] - ETA: 0s - loss: 1.3307\n",
            " mean perplexity: 4.216023009831537 \n",
            "\n",
            "205/205 [==============================] - 116s 565ms/step - loss: 1.3307\n"
          ]
        }
      ],
      "source": [
        "#Entrenemos GRU POR 20 epocas mas! (o hasta el early stopping)\n",
        "history_ppl = []\n",
        "hist = model2.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl,5,'my_model_GRU')], batch_size=2048)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_LlqmtEW1Hn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "model2 = keras.models.load_model('my_model_GRU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cargamos el mejor modelo y generamos 5 textos para ver que tan humano es!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- GRU ---\n",
            "dorian gray es lo que había encontrado por la cabeza de las cosas\n",
            "dorian gray es lo que había encontrado por la cabeza de las mujer\n",
            "dorian gray es lo que había encontrado por la cabeza de las manos\n",
            "dorian gray es lo que había encontrado con las mujeres de los ojo\n",
            "dorian gray es lo que había encontrado con las mujeres de las cos\n",
            "dorian gray es lo que había encontrado con las mujeres de las man\n",
            "dorian gray es lo que había encontrado con las mujeres de las muj\n",
            "dorian gray es lo que había encontrado con las mujeres de las \n",
            "c\n",
            "dorian gray es lo que había encontrado con las mujeres de las \n",
            "p\n",
            "dorian gray es lo que había encontrado con las mujeres de las pal\n"
          ]
        }
      ],
      "source": [
        "print('--- GRU ---')\n",
        "beam= beam_search(model2,num_beams=10,num_words=50,input=\"dorian gray es \",temp=10);\n",
        "for item in range(10):\n",
        "    print(decode(beam[item]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No es excelente, pero para ser un modelo tan secillo, entrenado por una hora, es bastante bueno."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
